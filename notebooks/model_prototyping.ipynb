{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1706a5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.8.0 _CudaDeviceProperties(name='NVIDIA GeForce GTX 960', major=5, minor=2, total_memory=4028MB, multi_processor_count=8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikolaj/.cache/pypoetry/virtualenvs/road-detection-model-g2s0wt3N-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5646df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir labels/valids/\n",
    "!mkdir labels/trains/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc4d8a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set...\n",
      "Converting training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 69863/69863 [00:07<00:00, 9401.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "Loading validation set...\n",
      "Converting validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [00:02<00:00, 3930.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def bdd2coco_detection(id_dict, labeled_images, fn):\n",
    "    images = list()\n",
    "    annotations = list()\n",
    "    counter = 0\n",
    "    for i in tqdm(labeled_images):\n",
    "        counter += 1\n",
    "        image = dict()\n",
    "        image['file_name'] = i['name']\n",
    "        image['height'] = 720\n",
    "        image['width'] = 1280\n",
    "        image['id'] = counter\n",
    "\n",
    "        empty_image = True\n",
    "\n",
    "        # Ensure 'labels' key exists\n",
    "        if 'labels' in i:\n",
    "            for label in i['labels']:\n",
    "                annotation = dict()\n",
    "                category = label['category']\n",
    "                if category == \"traffic light\":\n",
    "                    color = label['attributes']['trafficLightColor']\n",
    "                    category = \"tl_\" + color\n",
    "                if category in id_dict.keys():\n",
    "                    empty_image = False\n",
    "                    annotation[\"iscrowd\"] = 0\n",
    "                    annotation[\"image_id\"] = image['id']\n",
    "                    x1 = label['box2d']['x1']\n",
    "                    y1 = label['box2d']['y1']\n",
    "                    x2 = label['box2d']['x2']\n",
    "                    y2 = label['box2d']['y2']\n",
    "                    annotation['bbox'] = [x1, y1, x2-x1, y2-y1]\n",
    "                    annotation['area'] = float((x2 - x1) * (y2 - y1))\n",
    "                    annotation['category_id'] = id_dict[category]\n",
    "                    annotation['ignore'] = 0\n",
    "                    annotation['id'] = label['id']\n",
    "                    annotation['segmentation'] = [[x1, y1, x1, y2, x2, y2, x2, y1]]\n",
    "                    annotations.append(annotation)\n",
    "\n",
    "        if empty_image:\n",
    "            continue\n",
    "\n",
    "        images.append(image)\n",
    "\n",
    "    attr_dict[\"images\"] = images\n",
    "    attr_dict[\"annotations\"] = annotations\n",
    "    attr_dict[\"type\"] = \"instances\"\n",
    "\n",
    "    print('saving...')\n",
    "    json_string = json.dumps(attr_dict)\n",
    "    with open(fn, \"w\") as file:\n",
    "        file.write(json_string)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    label_dir=\"data/bdd100k/labels/det_20/\"\n",
    "    save_path=\"labels/\"\n",
    "\n",
    "\n",
    "    attr_dict = dict()\n",
    "    attr_dict[\"categories\"] = [\n",
    "        {\"supercategory\": \"none\", \"id\": 1, \"name\": \"pedestrian\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 2, \"name\": \"rider\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 3, \"name\": \"car\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 4, \"name\": \"bus\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 5, \"name\": \"truck\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 6, \"name\": \"bicycle\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 7, \"name\": \"motorcycle\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 8, \"name\": \"tl_G\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 9, \"name\": \"tl_R\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 10, \"name\": \"tl_Y\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 11, \"name\": \"tl_none\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 12, \"name\": \"traffic sign\"},\n",
    "        {\"supercategory\": \"none\", \"id\": 13, \"name\": \"train\"}\n",
    "    ]\n",
    "\n",
    "    attr_id_dict = {i['name']: i['id'] for i in attr_dict['categories']}\n",
    "\n",
    "    # create BDD training set detections in COCO format\n",
    "    print('Loading training set...')\n",
    "    with open(os.path.join(label_dir,\n",
    "                           'det_train.json')) as f:\n",
    "        train_labels = json.load(f)\n",
    "    print('Converting training set...')\n",
    "\n",
    "    out_fn = os.path.join(save_path,\n",
    "                          'bdd100k_labels_images_det_coco_train.json')\n",
    "    bdd2coco_detection(attr_id_dict, train_labels, out_fn)\n",
    "\n",
    "    print('Loading validation set...')\n",
    "    # create BDD validation set detections in COCO format\n",
    "    with open(os.path.join(label_dir,\n",
    "                           'det_val.json')) as f:\n",
    "        val_labels = json.load(f)\n",
    "    print('Converting validation set...')\n",
    "\n",
    "    out_fn = os.path.join(save_path,\n",
    "                          'bdd100k_labels_images_det_coco_val.json')\n",
    "    bdd2coco_detection(attr_id_dict, val_labels, out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dbaf2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|████████████████| 10000/10000 [00:01<00:00, 6377.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def coco_to_yolo(coco_json_path, cls_list_path, output_path, img_path, img_type):\n",
    "    # Load class names\n",
    "    with open(cls_list_path, \"r\") as file:\n",
    "        cls_names = file.read().strip().split('\\n')\n",
    "    cls_to_id = {name: idx for idx, name in enumerate(cls_names)}\n",
    "    \n",
    "    # Load COCO JSON\n",
    "    with open(coco_json_path) as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Create image and annotation dictionaries\n",
    "    images = {img[\"id\"]: img for img in coco_data[\"images\"]}\n",
    "    annotations = defaultdict(list)\n",
    "    for ann in coco_data[\"annotations\"]:\n",
    "        annotations[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    # Create output directory\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for img_id, anns in tqdm(annotations.items(), desc=\"Processing images\"):\n",
    "        img = images[img_id]\n",
    "        img_name = img[\"file_name\"]\n",
    "        img_w, img_h = img[\"width\"], img[\"height\"]\n",
    "        \n",
    "        # Create YOLO label file\n",
    "        label_file_path = Path(output_path) / (Path(img_name).with_suffix(\".txt\"))\n",
    "        with open(label_file_path, \"w\") as label_file:\n",
    "            for ann in anns:\n",
    "                if ann[\"iscrowd\"]:\n",
    "                    continue\n",
    "                \n",
    "                # Convert bounding box\n",
    "                x, y, w, h = ann[\"bbox\"]\n",
    "                x_center = (x + w / 2) / img_w\n",
    "                y_center = (y + h / 2) / img_h\n",
    "                width = w / img_w\n",
    "                height = h / img_h\n",
    "                \n",
    "                cls_id = ann[\"category_id\"]  # Assuming category_id starts from 1\n",
    "                \n",
    "                # Write to file\n",
    "                label_file.write(f\"{cls_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "    \n",
    "    print(\"Conversion completed.\")\n",
    "\n",
    "def main(config):\n",
    "    if config[\"datasets\"] == \"COCO\":\n",
    "        coco_to_yolo(\n",
    "            coco_json_path=config[\"label\"],\n",
    "            cls_list_path=config[\"cls_list\"],\n",
    "            output_path=config[\"output_path\"],\n",
    "            img_path=config[\"img_path\"],\n",
    "            img_type=config[\"img_type\"]\n",
    "        )\n",
    "    else:\n",
    "        print(\"Unknown datasets\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "#     config ={\n",
    "#         \"datasets\": \"COCO\",\n",
    "#         \"img_path\": \"data/bdd100k/images/100k/train\",\n",
    "#         \"label\": \"labels/bdd100k_labels_images_det_coco_train.json\",\n",
    "#         \"img_type\": \".jpg\",\n",
    "#         \"manipast_path\": \"./\",\n",
    "#         \"output_path\": \"labels/trains/\",\n",
    "#         \"cls_list\": \"data/bdd100k.names\",\n",
    "#         }\n",
    "    config = {\n",
    "        \"datasets\": \"COCO\",\n",
    "        \"img_path\": \"data/bdd100k/images/100k/val\",\n",
    "        \"label\": \"labels/bdd100k_labels_images_det_coco_val.json\",\n",
    "        \"img_type\": \".jpg\",\n",
    "        \"output_path\": \"labels/valids/\",\n",
    "        \"cls_list\": \"data/bdd100k.names\",\n",
    "    }\n",
    "\n",
    "    main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fa0ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    " import glob, os, shutil\n",
    "\n",
    "'''\n",
    "Sometimes your image data set might not match with your label data set.\n",
    "This code does the folowing\n",
    "(1) Go through your image data set\n",
    "(2) Search if the corresponding label file exist in the label data set. \n",
    "(3) If not, remove current image\n",
    "'''\n",
    "\n",
    "\n",
    "def copy_filter(label_dir,image_dir,target_dir_images,target_dir_labels):\n",
    "    for image in os.listdir(image_dir):\n",
    "        if image.endswith('jpg'):\n",
    "            image_name = os.path.splitext(image)[0]\n",
    "\n",
    "            # Corresponding label file name\n",
    "            label_name = image_name + '.txt'\n",
    "            image_path = image_dir + '/' + image_name + '.jpg'\n",
    "            if os.path.isfile(label_dir + '/' + label_name) == False:\n",
    "                print(\" -- DELETE IMAGE [Label file not found -- ]\")\n",
    "                \n",
    "                print(image_path)\n",
    "#                 os.remove(image_path)\n",
    "#             else:\n",
    "                target_images=target_dir_images+ '/' + image_name + '.jpg'\n",
    "                shutil.copy(image_path,target_dir_images )\n",
    "                print(\" --COPY IMAGE \"+target_images)\n",
    "\n",
    "\n",
    "    for label in os.listdir(label_dir):\n",
    "        if label.endswith('.txt'):\n",
    "            label_name = os.path.splitext(label)[0]\n",
    "\n",
    "            # Corresponding label file name\n",
    "            image_name = label_name + '.jpg'\n",
    "            label_path = label_dir + '/' + label_name + '.txt'\n",
    "            if os.path.isfile(image_dir + '/' + image_name) == False:\n",
    "                print(\" -- DELETE LABEL [Image file not found -- ]\")\n",
    "                print(label_path)\n",
    "#                 os.remove(label_path)\n",
    "#             else:\n",
    "                target_labels=target_dir_labels+ '/' + label_name + '.txt'\n",
    "                shutil.copy(label_path,target_labels )\n",
    "                print(\" --COPY lABELS \"+target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dir = '/labels/trains'\n",
    "image_dir = 'data/bdd100k/images/100k/train/'\n",
    "target_dir_images=\"bdd100k/images/trains\"\n",
    "target_dir_labels=\"bdd100k/labels/trains\"\n",
    "copy_filter(label_dir,image_dir,target_dir_images,target_dir_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "road-detection-model-py3.9",
   "language": "python",
   "name": "road-detection-model-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
